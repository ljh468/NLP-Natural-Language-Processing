{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4-1. Recurrent Neural Networks (RNN) with Keras.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPOM52eHA+HtRvaD63jYQd2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"D4mkPYxg_vrZ"},"source":["# Introduction to RNN(Recurrent Neural Networks)\n","\n","- 기본 아이디어\n","\n","    > 인간은 모든 생각을 밑바닥부터 시작하지 않는다. \n","    >\n","    > 지금 이 글을 읽는 당신도 매 단어를 그 전 단어들을 바탕으로 이해할 것이 분명하다. \n","    > 지금까지 봐왔던 것들을 모두 집어던지고 아무 것도 모르는 채로 생각하지 않을 것이다. 생각은 계속 나아가는 것이다.\n","    > \n","    > 전통적인 neural network이 이렇게 지속되는 생각을 하지 못한다는 것이 큰 단점이다.\n","    >\n","    > 예를 들어, 영화의 매 순간 일어나는 사건을 분류하고 싶다고 해보자. 전통적인 neural network는 이전에 일어난 사건을 바탕으로 나중에 일어나는 사건을 생각하지 못한다.\n","    >\n","    > Recurrent neural network (이하 RNN)는 이 문제를 해결하고자 하는 모델이다. RNN은 스스로를 반복하면서 이전 단계에서 얻은 정보가 지속되도록 한다.\n","\n","\n","- RNN(Recurrent Neural Network)은 시퀀스(Sequence) 모델입니다. 입력과 출력을 시퀀스 단위로 처리하는 모델입니다. \n","\n","    - 번역기를 생각해보면 입력은 번역하고자 하는 문장. 즉, 단어 시퀀스입니다. 출력에 해당되는 번역된 문장 또한 단어 시퀀스입니다. 이러한 시퀀스들을 처리하기 위해 고안된 모델들을 시퀀스 모델이라고 합니다. 그 중에서도 RNN은 딥 러닝에 있어 가장 기본적인 시퀀스 모델입니다.\n","\n","    - 지난 몇 년 동안, RNN은 음성 인식, 언어 모델링, 번역, 이미지 주석 생성 등등등등의 다양한 분야에서 굉장한 성공을 거두었다. \n","      - 참고: RNN으로 얻을 수 있는 놀라운 이점에 대한 논의는 Andrej Karpathy의 (The Unreasonable Effectiveness of Recurrent Neural Networks)[http://karpathy.github.io/2015/05/21/rnn-effectiveness/] \n","\n","- RNN은 이전 계산에 따라 출력이 달라지며 시퀀스의 모든 요소에 대해 동일한 작업을 수행하기 때문에 반복이라고 불린다.\n","\n","- RNN에 대해 생각할 수 있는 또 다른 방법은 그들이 지금까지 계산된 것에 대한 정보를 포착하는 \"메모리\"를 가지고 있다는 것이다.\n","\n","<br>\n"]},{"cell_type":"markdown","metadata":{"id":"3NbkckmR_0JJ"},"source":["\n","## 순환 신경망의 특징\n","\n","  - 입력 X를 받아서, 출력 Y를 반환합니다.\n","  - 순환구조를 가지고 있다; 어떤 레이어의 출력을 다시 입력으로 받는 구조를 말합니다.\n","  - 순환 신경망은 입력과 출력의 길이에 제한이 없습니다.\n","  - 순환 신경망은 이미지에 대한 설명을 생성하는 이미지 설명 생성, 문장의 긍정/부정을 판단하는 감성 분석, 하나의 언어를 다른 언어로 번역하는 기계 번역(Machine Translation) 등 다양한 용도로 활용됩니다.\n","\n","<img src='https://i.stack.imgur.com/WSOie.png'>"]},{"cell_type":"markdown","metadata":{"id":"lbrlJgPqAGEi"},"source":["\n","## Simple RNN \n","\n","### Model Architecture Diagram\n","\n","<br>\n","\n","<img src='https://theaisummer.com/static/2c376937397d142197de07495803cb54/29007/rnn-cell-time-unfold.png'>\n","\n","\n","__RNN Model Computation Mechanism__\n","\n","<img src = 'http://i.imgur.com/s8nYcww.png'>\n","\n","\n","\n","\n","### Simple RNN의 단점\n","\n","  - Vanishing Gradient Problem\n","    - RNN은 관련 정보와 그 정보를 사용하는 지점 사이 거리가 멀 경우 역전파시 그래디언트가 점차 줄어 학습능력이 크게 저하되는 문제\n","\n","<img src='http://i.imgur.com/H9UoXdC.png'>"]},{"cell_type":"markdown","metadata":{"id":"W5bhIG8qAJH9"},"source":["## LSTM(Long Short Term Memory Networks)\n","\n","### Simple RNN vs LSTM\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F99893B375ACB86A035DE41'>\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile30.uf.tistory.com%2Fimage%2F999F603E5ACB86A00550F0'>\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile5.uf.tistory.com%2Fimage%2F993A93495ACB86A02FFAA8'>\n","\n","### LSTM의 핵심 아이디어\n","\n","LSTM의 핵심은 cell state인데, 모듈 그림에서 수평으로 그어진 윗 선에 해당한다.\n","\n","Cell state는 컨베이어 벨트와 같아서, 작은 linear interaction만을 적용시키면서 전체 체인을 계속 구동시킨다. 정보가 전혀 바뀌지 않고 그대로 흐르게만 하는 것은 매우 쉽게 할 수 있다.\n","\n","LSTM은 cell state에 뭔가를 더하거나 없앨 수 있는 능력이 있는데, 이 능력은 gate라고 불리는 구조에 의해서 조심스럽게 제어된다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile29.uf.tistory.com%2Fimage%2F99C98C4F5ACB86A01FD4E5'>\n","\n","\n","\n","### 단계별로 보는 LSTM\n","\n","LSTM은 3개의 gate를 가지고 있고, 이 문들은 cell state를 보호하고 제어한다.   \n","\n","\n","1. 첫 단계(forget gate layer)\n","\n","LSTM의 첫 단계로는 cell state로부터 어떤 정보를 버릴 것인지를 정하는 것으로, sigmoid layer에 의해 결정된다. 그래서 이 단계의 gate를 \"forget gate layer\"라고 부른다. 이 단계에서는 $h_{t-1}$과 $x_{t}$를 받아서 0과 1 사이의 값을 $C_{t-1}$에 보내준다. \n","     \n","\n","  - 그 값이 1이면 \"모든 정보를 보존해라\"가 되고, 0이면 \"죄다 갖다버려라\"가 된다.\n","      - 예를 들어 cell state는 현재 주어의 성별 정보를 가지고 있을 수도 있어서 그 성별에 맞는 대명사가 사용되도록 준비하고 있을 수도 있을 것이다. 그런데 새로운 주어가 왔을 때, 우리는 기존 주어의 성별 정보를 생각하고 싶지 않을 것이다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile2.uf.tistory.com%2Fimage%2F9957DB445ACB86A02155EA'>\n","\n","<h4><center>LSTM의 forget gate layer</center></h4>\n","\n","2. 두번째 단계(input gate layer)\n","  - 다음 단계는 앞으로 들어오는 새로운 정보 중 어떤 것을 cell state에 저장할 것인지를 정한다. \n","      - 먼저, \"input gate layer\"라고 불리는 sigmoid layer가 어떤 값을 업데이트할 지 정한다. \n","      - 그 다음에 tanh layer가 새로운 후보 값들인 $\\widetilde{C}_t$ 라는 vector를 만들고, cell state에 더할 준비를 한다.\n","      - 이렇게 두 단계에서 나온 정보를 합쳐서 state를 업데이트할 재료를 만들게 된다.\n","      - 마지막으로 과거 state인 $C_{t-1}$를 업데이트해서 새로운 cell state인 $C_t$를 만든다. \n","        * 예를 들어 다시 언어 모델의 예제에서, 기존 주어의 성별을 잊어버리기로 했고, 그 대신 새로운 주어의 성별 정보를 cell state에 더하고 싶을 것이다\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile4.uf.tistory.com%2Fimage%2F99D969495ACB86A00BFC15'>\n","\n","<h4><center>LSTM의 input gate layer</center></h4>\n","\n","<img src = 'https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile9.uf.tistory.com%2Fimage%2F997589405ACB86A00CADEA'>\n","\n","<h4><center>LSTM의 cell state 업데이트</center></h4>\n","\n","3. 세번째 단계(output gate layer)\n","  - 마지막으로 무엇을 output으로 내보낼 지 정하는 일이 남았다. \n","      - 가장 먼저, sigmoid layer에 input 데이터를 태워서 cell state의 어느 부분을 output으로 내보낼 지를 정한다. \n","      - 그리고나서 cell state를 tanh layer에 태워서 -1과 1 사이의 값을 받은 뒤에 방금 전에 계산한 sigmoid gate의 output과 곱해준다. \n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=http%3A%2F%2Fcfile7.uf.tistory.com%2Fimage%2F99FB824C5ACB86A10D4182'>\n","\n","<h4><center>LSTM의 output gate layer</center></h4>\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mohvEmubAMVl"},"source":["# Recurrent Neural Networks (RNN) with Keras"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YF771x_NAd39","executionInfo":{"status":"ok","timestamp":1632490366916,"user_tz":-540,"elapsed":3,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"c29d982d-4054-436f-8242-fa0fe8b8be4a"},"source":["import time\n","\n","start = time.time()\n","print('시작시간:', time.ctime(start))"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["시작시간: Fri Sep 24 13:32:47 2021\n"]}]},{"cell_type":"markdown","metadata":{"id":"mxbUwCXrAe8k"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KgeTdhHaAjDp","executionInfo":{"status":"ok","timestamp":1632490382235,"user_tz":-540,"elapsed":8437,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"6695f094-9215-4ad1-e382-ea48aee667e0"},"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Activation, SimpleRNN, LSTM, GRU, Bidirectional\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.datasets import mnist\n","import numpy as np\n","\n","\n","# To prevent CUBLAS_STATUS_ALLOC_FAILED problem in tensorflow 2, the follwing codes are necessary.\n","\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["1 Physical GPUs, 1 Logical GPUs\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ONY9Vy38AkCJ","executionInfo":{"status":"ok","timestamp":1632490383190,"user_tz":-540,"elapsed":966,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"da6cb8a4-bf8d-4c03-d319-c4aa1793923f"},"source":["# Step 1: Data Preparation\n","\n","(x_train, y_train),(x_test, y_test) = mnist.load_data()\n","\n","num_labels = len(np.unique(y_train))\n","image_size= x_train.shape[1]\n","\n","# Reshaping for RNN \n","\n","x_train= np.reshape(x_train,[-1,image_size,image_size])\n","x_test= np.reshape(x_test,[-1,image_size,image_size])\n","\n","# Normalizing\n","x_train=x_train/255.\n","x_test = x_test/255.\n","\n","#One-hot encoding\n","\n","y_train=to_categorical(y_train)\n","y_test=to_categorical(y_test)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"M33qb_BNAlm7"},"source":["## Simple RNN with mnist"]},{"cell_type":"code","metadata":{"id":"EnxTqiGfAou5","executionInfo":{"status":"ok","timestamp":1632490398000,"user_tz":-540,"elapsed":384,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["# Step 2: Model Building\n","\n","# Hyperparameter setup\n","\n","n_steps = 28     # 28 rows\n","n_inputs = 28    # 28 cols\n","input_shape = (n_steps, n_inputs)  #    =  (image_size,image_size)\n","batch_size = 128\n","n_units = 30    # Number of neurons in a cell\n","dropout=0.2\n","epochs= 20\n","\n","# model\n","model = Sequential()\n","model.add(SimpleRNN(units=n_units,\n","                    dropout=dropout,\n","                    input_shape=input_shape))\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D-SktBTWAp2N"},"source":["RNN 분류기와 이전 두 모델인 ANN과 CNN 사이에는 두 가지 주요 차이가 있다.\n","\n","- 첫째, input_shape = (image_size, image_size), 이것은 실제로 input_ shape = (timesteps, input_dim) 또는 시간 단계 길이의 input_dim 디멘젼 벡터들의 시퀀스이다.\n","- 둘째, SimpleRNN 레이어를 사용하여 단위=256인 RNN 셀을 나타냅니다. 단위 변수는 출력 단위의 수를 나타냅니다.\n","\n","\n","CNN이 입력 기능 맵에서 커널의 컨볼루션으로 특징지어지는 경우, RNN 출력은 현재 입력뿐만 아니라 이전 출력 또는 숨겨진 상태의 함수이다.<br> 이전 출력도 이전 입력의 함수이므로 현재 출력도 이전 출력과 입력 등의 함수입니다."]},{"cell_type":"code","metadata":{"id":"5_b9mT-hBErn","executionInfo":{"status":"ok","timestamp":1632490524939,"user_tz":-540,"elapsed":376,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}}},"source":["# Step 3: Model Compile\n","\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x5-uFKZyBI2C","executionInfo":{"status":"ok","timestamp":1632490844701,"user_tz":-540,"elapsed":316930,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"18c4031c-91c0-4ec7-c015-8a724afe9a7f"},"source":["# Step 4: Model Fit\n","\n","model.fit(x_train, y_train, epochs=epochs, batch_size = batch_size)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 19s 34ms/step - loss: 1.3000 - accuracy: 0.5532\n","Epoch 2/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.7806 - accuracy: 0.7398\n","Epoch 3/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.6313 - accuracy: 0.7941\n","Epoch 4/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.5422 - accuracy: 0.8276\n","Epoch 5/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.4870 - accuracy: 0.8490\n","Epoch 6/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.4465 - accuracy: 0.8643\n","Epoch 7/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.4092 - accuracy: 0.8755\n","Epoch 8/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.3828 - accuracy: 0.8849\n","Epoch 9/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.3630 - accuracy: 0.8907\n","Epoch 10/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.3425 - accuracy: 0.8962\n","Epoch 11/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.3332 - accuracy: 0.8996\n","Epoch 12/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.3165 - accuracy: 0.9048\n","Epoch 13/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.3076 - accuracy: 0.9071\n","Epoch 14/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.2961 - accuracy: 0.9118\n","Epoch 15/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.2918 - accuracy: 0.9127\n","Epoch 16/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.2805 - accuracy: 0.9157\n","Epoch 17/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.2743 - accuracy: 0.9187\n","Epoch 18/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.2637 - accuracy: 0.9202\n","Epoch 19/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.2580 - accuracy: 0.9229\n","Epoch 20/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.2529 - accuracy: 0.9251\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3d70117c90>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KX7KwXWABJoD","executionInfo":{"status":"ok","timestamp":1632490845964,"user_tz":-540,"elapsed":1266,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"140a8db9-0422-4eba-826e-79d669a1fb0d"},"source":["# Step 5: Model evaluation\n","\n","__, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n","print(\"Test Accuracy: %.1f%%\" %(100*acc))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 1s 6ms/step - loss: 0.2039 - accuracy: 0.9419\n","Test Accuracy: 94.2%\n"]}]},{"cell_type":"markdown","metadata":{"id":"5lNFom0QBK3s"},"source":["### How to improve Simple RNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dTaGqoiJBMR9","executionInfo":{"status":"ok","timestamp":1632491169702,"user_tz":-540,"elapsed":323744,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"1393185c-a11b-4889-9d4a-feda58dbffb1"},"source":["# Hyperparameter setup\n","\n","n_steps = 28     # 28 rows\n","n_inputs = 28    # 28 cols\n","input_shape = (n_steps, n_inputs)  #    =  (image_size,image_size)\n","batch_size = 128\n","n_units = 256    # Number of neurons in a cell\n","dropout=0.2\n","epochs= 20\n","\n","# Step 2: Model Building\n","model = Sequential()\n","model.add(SimpleRNN(units=n_units,\n","                    dropout=dropout,\n","                    input_shape=input_shape))\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))\n","\n","# Step 3: Model Compile\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","\n","# Step 4: Model Fit\n","model.fit(x_train, y_train, epochs=epochs, batch_size = batch_size)\n","\n","# Step 5: Model evaluation\n","\n","__, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n","print(\"\\nTest Accuracy: %.1f%%\" %(100*acc))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 17s 34ms/step - loss: 0.4837 - accuracy: 0.8476\n","Epoch 2/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.2314 - accuracy: 0.9298\n","Epoch 3/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.1836 - accuracy: 0.9447\n","Epoch 4/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.1580 - accuracy: 0.9532\n","Epoch 5/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.1422 - accuracy: 0.9579\n","Epoch 6/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.1339 - accuracy: 0.9597\n","Epoch 7/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.1270 - accuracy: 0.9628\n","Epoch 8/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.1204 - accuracy: 0.9645\n","Epoch 9/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.1119 - accuracy: 0.9671\n","Epoch 10/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.1097 - accuracy: 0.9676\n","Epoch 11/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.1059 - accuracy: 0.9688\n","Epoch 12/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.1013 - accuracy: 0.9701\n","Epoch 13/20\n","469/469 [==============================] - 15s 32ms/step - loss: 0.0992 - accuracy: 0.9700\n","Epoch 14/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.0951 - accuracy: 0.9725\n","Epoch 15/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.0948 - accuracy: 0.9721\n","Epoch 16/20\n","469/469 [==============================] - 16s 34ms/step - loss: 0.0916 - accuracy: 0.9723\n","Epoch 17/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.0928 - accuracy: 0.9727\n","Epoch 18/20\n","469/469 [==============================] - 15s 33ms/step - loss: 0.0955 - accuracy: 0.9720\n","Epoch 19/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.0916 - accuracy: 0.9730\n","Epoch 20/20\n","469/469 [==============================] - 16s 33ms/step - loss: 0.0875 - accuracy: 0.9742\n","79/79 [==============================] - 1s 6ms/step - loss: 0.0812 - accuracy: 0.9782\n","\n","Test Accuracy: 97.8%\n"]}]},{"cell_type":"markdown","metadata":{"id":"Aaaa0nF7BNFt"},"source":["많은 심층 신경 네트워크에서는 RNN 계열의 다른 구성원이 더 일반적으로 사용된다. 예를 들어, LSTM(Long Short-Term Memory)은 기계 번역 및 질문 답변 문제 모두에 사용되었다. LSTM은 장기 의존성 또는 현재 출력물에 대한 관련 과거 정보 기억 문제를 다룬다."]},{"cell_type":"markdown","metadata":{"id":"O-vE1HwFBRe8"},"source":["RNN 또는 SimpleRNN과 달리 LSTM 셀의 내부 구조는 더 복잡하다."]},{"cell_type":"markdown","metadata":{"id":"W-TbxlkiBUgl"},"source":["- LSTM은 현재 입력과 과거 출력 또는 숨겨진 상태를 사용할 뿐만 아니라 한 셀에서 다른 셀로 정보를 전달하는 셀 상태 s t 를 도입한다.\n","\n","- 셀 상태 사이의 정보 흐름은 게이트, 입력 게이트 및 출력 게이트의 세 가지 게이트에 의해 제어됩니다.\n","\n","- 세 개의 관문은 결정의 효과가 있다.\n","    - 어떤 정보가 유지되거나 대체되어야 하는가?\n","    - 현재 셀 상태 또는 출력에 기여해야 하는 과거 및 현재 입력 정보의 양.\n","- LSTM() 레이어는 SimpleRNN()의 드롭인 대체물로 사용할 수 있다.\n","\n","- LSTM이 당면한 작업에 비해 과잉 처리될 경우 게이트 순환 장치(GRU)라는 간단한 버전을 사용할 수 있다.\n","    - GRU는 셀 상태와 은닉 상태를 함께 결합하여 LSTM을 단순화합니다.\n","    - GRU는 또한 게이트 수를 1개 감소시킨다.\n","    - GRU() 함수는 SimpleRNN()에 대한 드롭다운 대체품으로 사용할 수도 있습니다.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Jgi1ZDUxBl5z"},"source":["- RNN을 구성하는 다른 많은 방법이 있습니다.\n","\n","    - 한 가지 방법은 양방향 RNN 모델을 만드는 것이다. 기본적으로 RNN은 현재 출력이 과거 상태와 현재 입력에 의해서만 영향을 받는다는 점에서 단방향입니다.\n","    - 양방향 RNN에서 미래 상태는 정보가 역류하도록 허용하여 현재 및 과거 상태에 영향을 미칠 수 있다. 이전 출력은 수신된 새 정보에 따라 필요에 따라 업데이트됩니다.\n","        - 포장 함수를 호출하여 양방향으로 RNN을 만들 수 있습니다.\n","        - 예를 들어 양방향 LSTM의 구현은 양방향(LSTM)이다.\n","\n","- 모든 유형의 RNN에서 장치의 수를 늘리면 용량도 증가합니다.\n","- 용량을 늘리는 또 다른 방법은 RNN 레이어를 쌓는 것입니다.\n","- 그러나 일반적으로 모델의 용량은 필요한 경우에만 증가해야 한다는 점에 유의해야 한다.\n","    - 용량이 초과되면 과적합이 발생할 수 있으며, 결과적으로 예측 중 교육 시간이 길어지고 성능이 저하될 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"TvU7qvD-CBOF"},"source":["## LSTM with mnist"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M0EuMp7mCXLR","executionInfo":{"status":"ok","timestamp":1632491254350,"user_tz":-540,"elapsed":84652,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"cd58d526-b539-493f-d2a7-6a43614766a0"},"source":["# Parameters for LSTM network\n","n_units = 30\n","\n","# Build LSTM network\n","model = Sequential()\n","model.add(LSTM(n_units ,\n","               dropout=dropout,\n","               input_shape=input_shape))\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(x_train, y_train, epochs=epochs, batch_size = batch_size)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 8s 8ms/step - loss: 1.1649 - accuracy: 0.6193\n","Epoch 2/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.5305 - accuracy: 0.8351\n","Epoch 3/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3566 - accuracy: 0.8916\n","Epoch 4/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2727 - accuracy: 0.9182\n","Epoch 5/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2237 - accuracy: 0.9330\n","Epoch 6/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1931 - accuracy: 0.9419\n","Epoch 7/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1736 - accuracy: 0.9478\n","Epoch 8/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1564 - accuracy: 0.9518\n","Epoch 9/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1431 - accuracy: 0.9567\n","Epoch 10/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1317 - accuracy: 0.9603\n","Epoch 11/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1249 - accuracy: 0.9622\n","Epoch 12/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1180 - accuracy: 0.9642\n","Epoch 13/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1099 - accuracy: 0.9669\n","Epoch 14/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1033 - accuracy: 0.9686\n","Epoch 15/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1004 - accuracy: 0.9696\n","Epoch 16/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0953 - accuracy: 0.9711\n","Epoch 17/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0909 - accuracy: 0.9724\n","Epoch 18/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0889 - accuracy: 0.9732\n","Epoch 19/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0851 - accuracy: 0.9743\n","Epoch 20/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0820 - accuracy: 0.9753\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3cfee4ba10>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5LOQ7VMCZOG","executionInfo":{"status":"ok","timestamp":1632491256724,"user_tz":-540,"elapsed":1355,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"21c9a242-95a5-4be2-8034-159f96eda827"},"source":["# Step 5: Model evaluation\n","\n","__, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n","print(\"Test Accuracy: %.1f%%\" %(100*acc))"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9770\n","Test Accuracy: 97.7%\n"]}]},{"cell_type":"markdown","metadata":{"id":"iWc_MGEpCa3-"},"source":["## GRU with mnist"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpLG3JTqCcWf","executionInfo":{"status":"ok","timestamp":1632491334597,"user_tz":-540,"elapsed":77875,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"31b1c14f-bc57-4996-ddf3-648729bc12e3"},"source":["# Parameters for GRU network\n","n_units = 30\n","\n","# Build GRU network\n","model = Sequential()\n","model.add(GRU(n_units ,\n","               dropout=dropout,\n","               input_shape=input_shape))\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(x_train, y_train, epochs=epochs, batch_size = batch_size)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 6s 8ms/step - loss: 1.3022 - accuracy: 0.5533\n","Epoch 2/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.5797 - accuracy: 0.8150\n","Epoch 3/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3901 - accuracy: 0.8805\n","Epoch 4/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.3086 - accuracy: 0.9092\n","Epoch 5/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2621 - accuracy: 0.9233\n","Epoch 6/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2323 - accuracy: 0.9307\n","Epoch 7/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.2083 - accuracy: 0.9387\n","Epoch 8/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1911 - accuracy: 0.9436\n","Epoch 9/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1740 - accuracy: 0.9474\n","Epoch 10/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1622 - accuracy: 0.9516\n","Epoch 11/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1504 - accuracy: 0.9557\n","Epoch 12/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1411 - accuracy: 0.9586\n","Epoch 13/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1335 - accuracy: 0.9605\n","Epoch 14/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1251 - accuracy: 0.9632\n","Epoch 15/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1213 - accuracy: 0.9640\n","Epoch 16/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1167 - accuracy: 0.9643\n","Epoch 17/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1101 - accuracy: 0.9673\n","Epoch 18/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1062 - accuracy: 0.9686\n","Epoch 19/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.1033 - accuracy: 0.9692\n","Epoch 20/20\n","469/469 [==============================] - 4s 8ms/step - loss: 0.0985 - accuracy: 0.9705\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3cfeb79590>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bBsQ_GFQCdP7","executionInfo":{"status":"ok","timestamp":1632491335636,"user_tz":-540,"elapsed":1041,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"72036cc7-a1f9-4760-ed98-9c7dc5fa32f6"},"source":["# Step 5: Model evaluation\n","\n","__, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n","print(\"Test Accuracy: %.1f%%\" %(100*acc))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 1s 4ms/step - loss: 0.0833 - accuracy: 0.9752\n","Test Accuracy: 97.5%\n"]}]},{"cell_type":"markdown","metadata":{"id":"eK1fROqTCeWZ"},"source":["## Bidirectional LSTM"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lWIMh3TMCfpJ","executionInfo":{"status":"ok","timestamp":1632491486403,"user_tz":-540,"elapsed":150769,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"c6ea280a-813d-4c08-a524-ba334b029b66"},"source":["# Parameters for LSTM network\n","n_units = 30\n","\n","# Build LSTM network\n","model = Sequential()\n","model.add(Bidirectional(LSTM(n_units, \n","                             dropout=dropout,\n","                             input_shape=input_shape), \n","                        merge_mode='sum'))\n","model.add(Dense(num_labels))\n","model.add(Activation('softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Fit the model\n","model.fit(x_train, y_train, epochs=epochs, batch_size = batch_size)\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","469/469 [==============================] - 11s 16ms/step - loss: 0.9335 - accuracy: 0.6928\n","Epoch 2/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.3369 - accuracy: 0.8961\n","Epoch 3/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.2257 - accuracy: 0.9319\n","Epoch 4/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.1763 - accuracy: 0.9471\n","Epoch 5/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.1484 - accuracy: 0.9546\n","Epoch 6/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.1295 - accuracy: 0.9610\n","Epoch 7/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.1166 - accuracy: 0.9643\n","Epoch 8/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.1029 - accuracy: 0.9687\n","Epoch 9/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0960 - accuracy: 0.9704\n","Epoch 10/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0894 - accuracy: 0.9721\n","Epoch 11/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0831 - accuracy: 0.9740\n","Epoch 12/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0788 - accuracy: 0.9759\n","Epoch 13/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0754 - accuracy: 0.9767\n","Epoch 14/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0707 - accuracy: 0.9784\n","Epoch 15/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0672 - accuracy: 0.9789\n","Epoch 16/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0655 - accuracy: 0.9794\n","Epoch 17/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0621 - accuracy: 0.9807\n","Epoch 18/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0596 - accuracy: 0.9814\n","Epoch 19/20\n","469/469 [==============================] - 7s 16ms/step - loss: 0.0583 - accuracy: 0.9819\n","Epoch 20/20\n","469/469 [==============================] - 7s 15ms/step - loss: 0.0548 - accuracy: 0.9824\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3cfc3956d0>"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrLWAX1SCg12","executionInfo":{"status":"ok","timestamp":1632491488099,"user_tz":-540,"elapsed":1351,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"2e2d25d3-681a-4ca6-8046-ea271fbf8c33"},"source":["# Step 5: Model evaluation\n","\n","__, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n","print(\"Test Accuracy: %.1f%%\" %(100*acc))"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["79/79 [==============================] - 1s 7ms/step - loss: 0.0518 - accuracy: 0.9830\n","Test Accuracy: 98.3%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MSvx8J5gCiHp","executionInfo":{"status":"ok","timestamp":1632491488099,"user_tz":-540,"elapsed":4,"user":{"displayName":"이재훈","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghn1YVfD2yXCylStMwpRhLWW5v0bbynr4TSqcOQQQ=s64","userId":"14270995088772057531"}},"outputId":"fe83e927-9844-4422-8a98-16cebf7111a3"},"source":["end = time.time()\n","print('종료시간: ', time.ctime(end))\n","print('경과시간(분): ', ((end-start)/60))"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["종료시간:  Fri Sep 24 13:51:28 2021\n","경과시간(분):  18.68283868630727\n"]}]},{"cell_type":"code","metadata":{"id":"AGzCtQeGCjeq"},"source":[""],"execution_count":null,"outputs":[]}]}